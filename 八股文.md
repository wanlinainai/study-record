# 八股文

## Java基础

### 1. synchronized和ReentranLock？

相同点：都是可重入锁。

区别：

- synchronized是Java的内置属性，但是ReentranLock是通过Java来进行实现。
- synchronized是自动获取锁和自动释放锁，但是Lock是手动进行获取锁和释放锁。
- synchronized是非公平锁，而Lock是可以实现公平锁和非公平锁。

> synchronized加锁的时候是公平锁还是非公平锁？原理呢？
>
> 用的是非公平锁。
>
> JVM在管理等待锁的线程时，并不遵循先来先服务的原则。JVM和操作系统的调度器并不能保证拿一个线程会首先获取到锁。意味着刚请求锁的线程可能会在已经等待较长时间的线程之前获得锁资源。
>
> 设计的原因是处于性能考虑。非公平锁通常比公平锁具有更高的吞吐量，因为维护一个等待队列并确保按顺序获得锁的开销。尽管synchronized非公平锁可能导致某一些线程饥饿（就是某一些线程永远获取不到锁），但是在实际应用中，由于大多数锁持有时间比较短，这种情况出现的频率不高。JVM的锁优化机制（偏向锁、轻量级锁、锁膨胀）以及操作系统底层线程调度策略也会有助于减少饥饿问题的发生。



## 计算机网络

### 1. TCP三次握手和四次挥手的过程









## JVM

### 1. Java类加载机制

主要就是3部分。加载、链接、初始化。

#### 加载

将代码加载进JVM中，主要就是将.class文件加载进JVM虚拟机。

#### 链接

验证、准备、解析。

验证：校验类的正确性和完整性，保证JVM的规范。

准备：将static关键字修饰的变量加载到内存中。

解析：将类的符号引用转换成直接引用。

#### 初始化

1、遇到new、getstatic、putstatic等修饰的，读取静态字段，或者是调用一个类的静态方法。

2、使用反射进行创建对象 的时候会进行初始化。

3、如果初始化一个类的时候，它的父类还没有被初始化，那么会先初始化它的父类。

4、Main主类的初始化。

### 2. 有几种类加载器？

最顶层的Bootstrap ClassLoader，扩展类加载器Extension ClassLoader，应用层的类加载器Application ClassLoader。

### 3. JVM垃圾回收器

主要是G1和CMS。

#### G1

G1会将Java堆分成一个个的region区域，年轻代采用的是标记-复制算法，在老年代中采用的是标记-整理算法。避免内存碎片的产生。在jdk1.9中作为默认的垃圾回收器，但是相较于CMS，它的硬件要求相对较大，比如最基本的内存需要4GB。

执行步骤：

当Eden区用尽之后开始进行年轻代的回收过程，G1的年轻代收集阶段是一个并行的独占式收集器。G1GC暂停所有应用程序线程，启动多线程执行年轻代回收。将存货对象移动到Survivor区或者是老年区，也可能是两者都有。

当堆内存使用达到一定值（45%）时，开始老年代并发回收标记过程。

标记完成之后立马开始混合回收过程。G1 GC从老年区间移动存货对象到空闲区域，这些空闲区间也就会成为老年代的一部分。和年轻代相比，老年代G1回收器和其他的GC不同，G1老年代回收器不需要进行整个老年代回收，一次只需要扫描/回收一小部分老年代Region即可。

#### CMS

采用的默认就是标记-清除算法，

默认就是4步。

初始标记：标记所有从GCRoot直接可达的对象，暂停所有的应用线程，由于只能标记直接可达的对象，速度很快。

并发标记：从初始阶段遍历整个对象，标记出所有可达的对象，GC线程和应用线程同时进行。

预处理：处于并发标记和重新标记之间，并发执行，减少重新标记的工作量。

重新标记：修改并发标记阶段由于线程继续运行而产生的更改，需要Stop The World。

并发清理：GC清除不可达对象。

**优缺点**

优点：并发、低停顿。

缺点：

1、对于CPU十分敏感。在并发阶段不会导致用户线程停顿，但是会占用一部分线程是的其他的应用线程变得缓慢。

2、无法处理浮动垃圾。在最后一步并发清理的时候，用户线程执行也会产生垃圾，但是这部分的垃圾在标记之后，只有等到下一次的GC时候才会清理。

3、空间碎片太多。由于采用的是标记-清除算法，会产生内存碎片，对于大对象的空间分配带来很大的麻烦。

### 4. JVM内存区域

本地方法栈、虚拟机栈、程序计数器是线程私有的；堆、方法区、运行时常量池是线程共享的。

1、程序计数器。用于记录当前JVM正在执行的字节码指令的地址。为每一个线程维护一个计数器，用于指示下一条要被执行的字节码指令的位置。

2、Java虚拟机栈。存储局部变量、对象引用。

3、本地方法栈。存放的是本地方法的参数和局部变量。

4、Java堆。存储对象实例的运行时数据区。

5、方法区。存储已经被加载的类信息、常量、静态变量。

6、运行时常量池。

## Java集合

### 1. HashMap和HashTable以及ConcurrentHashMap区别？

HashMap是非线程安全的。HashTable是线程安全的 ，原因是直接加synchronized修饰。

ConcurrentHashMap在JDK1.8之前使用分段锁来保证线程安全，默认将Hash表分成16个桶，在加锁的时候针对于每一个分片进行加锁，其他的分片不受影响。1.8之后采用了CAS + synchronized进行保证线程安全，将对于整个Map的加锁降低到了单个桶。

### 2. HashMap数据结构什么样子？

数组 + 链表。

常用的哈希函数解决冲突叫做链地址法，就是将数组和链表组合到一起，发挥了两者的优势，我们可以理解成链表的数组，在JDK1.8的时候通过hash函数获取到数组的位置，之后每一个数组的每一个节点都是链表，从数组中找到链表就简单了，之后如果数组数量达到64，同时链表的长度达到8的时候就会转换成红黑树。

## RocketMQ

### 1. RocketMQ的结构是怎么样子的？

主要就是包含了四个部分：Producer、COnsumer、NameServer、Broker。以下是关系展示图：

![image-20240215190624858](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20240215190624858.png)

- Producer:消息生产者，负责将消息发送到Broker。
- NameServer：负责维护Broker的元数据信息，包含Broker地址、Topic、Queue等信息。当然，producer 和 COnsumer是需要连接到这个NameServer获取到Broker 获取Broker地址信息。
- Broker：消息中转服务器，负责存储转发消息，RockMQ支持多个Broker构成集群，每个Broker都拥有独立的存储空间和消息队列。
- Consumer：消息消费者，负责从Broker读取消息。
- Topic：消息主题，是消息的逻辑分类单位，Producer将消息发送到特定的 Topic中，Consumer从指定的Topic中消费消息。
- Message Queue:消息队列，是Topic的物理实现。一个Topic可以存在多个Queue，生产者发送的消息会被存储在Queue中，消费者从指定的Queue中读取响应的消息。

### 2. RocketMQ的事务消息是如何实现的

其实这个问题也是比较简单的。

最主要的是TransactionListener接口实现的。

以下是最主要的执行步骤：

![image-20240215194943762](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20240215194943762.png)

消息发送方发送消息将消息发送到Broker，当然此时发送的是半消息，“half Message”，此时这条消息并不能被消费，如果本地事务执行完成，就会通知RocketMQ Broker提交该事务消息，这条半消息就可以被消费；否则，将这条半消息删除，从而保证消息不会被消费者消费。

#### 如果长时间没有收到COMMIT或者ROLLBACK怎么办？

本身Broker 是会重新进行请求，重新发送请求进行回查，如果应用程序在指定时间内还是没有响应，RocketMQ会将该条消息标记成“UNKNOWN”状态。

在标记成“UNKNOWN”状态的事务消息中，如果应用程序有了明确的结果，还是可以向MQ发送COMMIT或者ROLLBACK。

但是MQ不会一直等待下去，如果时间到了，RocketMQ会自动回滚消息，会将事务消息删除。

#### 第一次发送半消息发送失败了怎么办？

在事务消息的一致性法案中，我们是先发送半消息，在做我们的业务操作。所以如果半消息发送失败了，业务操作并不会执行，所以不存在一致性问题。

### 3. RocketMQ如何保证消息的顺序性？

保证消息的顺序性主要是两种方式：生产者保证和消费者保证。

生产者顺序发送：

需要注意在我们的Send方法中需要传入MessageQueueSelector。

```java
SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
    @Override
    public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
        Integer id = (Integer) arg;
        int index = id % mqs.size();
        return mqs.get(index);
    }
}, orderId);
```

 如此一来，我们就可以将消息发送到同一个队列中。但是需要注意的是，这里需要使用同步发送的方式。

消费者顺序消费：

原生的RocketMQ提供了两种消费方式，有序消费模式MessageListenerOrderly和并发消费模式MessageListenerConsurrently。所以如果我们需要实现顺序消费，需要使用有序消费模式MessageListenerOrderly接收消息。

```java
consumer.registerMessageListener(new MessageLsitenerOrderly() {
   @Overide
    public ConsumerOrderlyStatus consumerMessage(List<MessageExt> msgs, COnsumerOrderlyContext Context) {
        System.out.println("receive order msg:" + new String(msgs.get(0).getBody()));
        return ConsumerOrderlyStatus.SUCCESS;
    }
});
```

 我们使用上述方式注册一个消费之后，为了使得一个队列中的有序消息可以被顺序消费，就要保证RocketMQ的Broker只会将消息发送到同一个消费者上，这时候就需要**加锁**了。

实现中，RocketMQ中自带的ConsumerMessageOrderlyService初始化的时候，会启动一个定时任务，会尝试向Broker为当前的消费者和申请分布式锁。如果获取成功，那么后续的消息将只会发送给这个Consumer。

接下来在消息拉取的过程中，消费者会一次性的拉取多条消息，放入到ProcessQueue。同时将消息提交到消费线程池进行执行。

RocketMQ在消费的过程中，需要申请MessageQueue锁，确保在同一时间一个队列只能有一个线程处理。

在MessageQueue锁之后，就可以从ProcessQueue中依次拉取一批消息了，但是在整个过程中，为了保证消息不回出现重复消费，我们还需要对ProcessQueue加锁。

> 原因解释：我们已经对MessageQueue加锁了，那么这个ProcessQueue不加锁可以吗？其实按照正常的情况下是可以的，但是也是有很多其他元素可能导致消息的不顺序消费，比如我们的生产者和消费者都是可以发生数量变化的，如果我们在消费的时候又添加了结果消费者，那么会出现重平衡的问题，某一个队列原本是属于消费者A来进行消费的，但是现在却是消费者B来进行消费。
>
> 此时客户端A将Broker锁释放，在这个解锁的过程中，需要保证消息不能再消费过程中被移除了，因为如果客户端A可能正在处理一部分消息，但是位点信息还没有更新，客户端B立马去消费队列中的消息，那存在一部分数据会被重复消费。
>
> 解决方案是在ProcessQueue上加锁，也就是说解锁的线程也是需要尝试ProcessQueue进行加锁，加锁成功之后才可以解锁操作。避免消息重复消息。

### 4. RocketMQ如何保证消息不丢失？

如果想要保证消息不丢失，想要完全保证的情况基本是不可能的。但是我们可以尽量减少这种情况出现。生产者、消费者、Broker都需要配合使用，尽可能做到最大程度的优化。

在生产者一端，消息发送分成同步发送和异步发送两种，同步的情况下，消息的发送会同步阻塞等待Broker返回结果，在Broker确认收到确认之后，生产者才会拿到SendResult。如果这个过程出现问题，那么就说明是可能消息发送出现问题。

但是Broker并不会直接将消息刷新到磁盘上，也是存在两种刷盘策略，分别是同步刷盘和异步刷盘， 而异步刷盘是先将数据存储在内存中，之后通过异步刷盘的方式将数据写入磁盘中。如果想保证消息不丢失，那么这个部分就需要将异步刷新磁盘改编成同步刷新磁盘，

```shell
# 默认情况是 ASYNC_FLUSH
flushDiskType = SYNC_FLUSH
```

当然， 上面的是同步发送消息，如果是异步发送消息的情况，那么我们生产者需要重写SendCallback的onSuccess和onException方法，用于给Broker进行回调。在这个方法中实现消息的确认或者是重新发送。

为了保证消息不丢失，我们的RocketMQ肯定是集群部署，Broker通常是一主多从的搭配，并且回采用主从复制的方式进行数据复制。

Broker的这个主从复制特点是先写入到master节点中，其余的从节点会从主节点直接异步处理。所以问题就是出现在这个地方，如果说master节点突然挂了，那么slave节点就不会进行刷盘复制的操作。原本是将数据保存在master节点上就会返回确认的结果。那么此时如果我们修改的话需要将返回确认结果的时机设置成复制完slave的时候，

```shell
## 默认是ASYNC_MASTER
brokerRole=SYNC_MASTER
```

消费者端，我们需要确认在消息拉取并且消费成功之后在给我们的Broker返回ACK 。就可以保证消息不丢失，如果一直没有收到的话，那么我们就重试。

### 5. RocketMQ如何实现延时消息？

RocketMQ是天然支持延时消息的，延迟消息写入到Broker之后，不会立刻被消费者消费，需要等待指定的时间后才可以被消费处理掉，称之为延迟消息。

当消息发送到Broker后，Broker会将消息根据延迟级别进行存储，RocketMQ的延迟消息实现方式是：将消息存储到内存中，然后使用Timer定时器进行消息的延迟处理，到达指定的时间之后在存储到磁盘上，最后投递给消费者。

但是在RocketMQ并不支持随意时间延时的，5.0之前只支持1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 这几个时长。

**在5.0版本时，新增了基于时间轮实现的定时消息。**

```java
// 创建一个消息生产者
DefaultMQProducer producer = new DefaultMQProducer("ProducerGroupName");
producer.setNamesrvAddr("localhost:9876");
producer.start();

Message message = new Message("TopicTest", "TagA", "Hello ROcketMQ".getBytes(RemotingHelper.DEFAULT_CHARSET));
// 构建延迟等级是3，即延迟10s
message.setDelayTimeLevel(3);

// 消息发送
SendResult sendResult = producer.send(message);
System.out.println("%s%n",sendResult);
```

### 6. RocketMQ有几种集群方式

3种，单Master模式、多Master模式以及多Master多Slave模式。

单Master集群模式，这是一种最简单的集群模式，知识包含一个Master节点和若干个Slave节点，所有写入的操作都是有Master节点完成，Slave节点主要是用于提供读取服务。当MAster节点宕机的话，集群就无法使用了。

多MAster模式，这是一种配置简单的集群模式，这种模式包含多个Master节点，没有Slave节点。单个Master宕机或者重启的话对应用没有影响，性能很高，缺点是单台机器宕机期间，这台机器上没有被消费的消息在机器恢复之前不可订阅，消息的实时性收到了影响。

多Master多Slave集群模式，这种集群模式包含多个Master多个Slave节点，每一个Master节点都可以处理写入操作，并且有一套自己的SLave节点。当其中一个Master节点宕机之后，消费者仍然可以从SLave消费。优点是数据与服务没有单点故障，Master宕机的情况下，消息没有延迟，服务可用性与数据可靠性比较高。缺点就是性能比异步复制模式略低（大约10%左右），发送单个消息的延迟会增高，并且目前版本在主节点宕机之后，备机不能作为主机使用。

### 7. 介绍一下RocketMQ的工作流程

![image-20240221005854082](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20240221005854082.png)

组成部分是只有四种：NameServer、Broker、Producer、Consumer四种。

1. 启动NameServer，等待Producer、Consumer和Broker的注册。
2. 启动Broker，注册到NameServer，定时发送心跳包，心跳包中包含：Broker的IP、Port等。Topic信息以及Broker和Topic的映射。
3. 启动Producer，启动的时候先随机和集群中的NameServer中的一个建立联系，从NameServer中获取到这个Producer需要的Topic所在的Broker地址，然后从队列列表中选择一个队列，与队列所在的Broker建立联系，进行消息的发送。
4. 当我们的Broker与Producer建立联系之后，如果是同步复制，Master需要先将内容同步到SLave节点，然后返回一个“写成功”的结果，同时如果是同步刷盘策略，还需要先将消息写入到磁盘中，再返回“写成功”的结果，要是配置的是异步刷盘和异步复制的话，对那个写入到Master之后就会返回成功。
5. 启动Consumer，先随机个NameServer建立连接，获取到Topic的Broker信息，与Broker建立联系，之后获取消息即可。



## 简历回答

### 项目

项目简述：

首先先介绍一下整体的项目是针对于学校中的同学以及教职工的，提供一个类似于校园墙的系统。

1、登录部分。整个项目并没有采用账号密码登录，采用的是微信公众号登录，大概的流程：

- 首先，用户点击获取二维码，我们会给前端展示一个二维码，而这个二维码是携带了一个随机的code值的，为什么需要携带这个Code，我们的这个code是与用户的Channel绑定的，一个用户绑定了一个Channel，（如果没有这个code和Channel绑定，用户在扫码登录之后其实还需要调用回调接口，那么就不知道谁对应的谁的Channel）。在用户获取二维码的时候生成二维码，这个code和Channel是存放在一个Map中的，那么就需要考虑线程安全，同时为了保证大量用户长时间不登录导致Map过大，还需要加上过期策略，将最开始未登录的用户进行删除。我们设置的大小是10000.
- 用户扫码关注之后，后端会在Redis中更新上线列表，也会在本地存储一份uid-->Channel的Map映射。方便生成Token以及推送消息。

> 考虑的难点：因为我们的项目是单机的，所以说如果项目以后扩展到了分布式项目。如果负载均衡没有负载到同一台机器上，那么这个用户的Channel是没有存储的，当然可能存在很多解决方案，但是都不适合，比如如果使用Redis存储，到时间从这个Redis中取出的话其实根本就不是同一个Channel，序列化和反序列化不是同一个东西，所以这部分还在考虑中。

2、消息部分。在消息部分也是存在很多细节。为了保证消息的多样性，我们使用了许多了消息类型：文字类型、图片类型、文件上传、表情包等。为了处理许多的消息类型，我们使用抽象工厂模式+策略模式进行处理。

- 定义一个存放策略的工厂类MessageFactory，其中包含两个方法，一个是注册消息处理器的register方法和通过消息类型通过消息类型来进行获取对应的处理器的方法。
- 之后重新定义一个AbstractMessageHandler，用来单独抽象出来，使用PostConstract，初始化方法将所有的策略模式注册进消息工厂。这一层为什么会抽象出来，其实也是为了定义各个消息处理器的规范，每一个消息处理器需要实现那些方法。

3、

### 八股文

#### 分布式事务

分布式事务指的是涉及到分布式系统中的多个数据库和多个应用程序之间的事务处理，这些数据库和应用程序可能分布在不同的机器上，而我们的事务只能在单个数据库中实现统一提交和回滚。主要的方案其实还是挺多的，不过大多数都是按照不同的需求，事务方案达到的效果不同，比如强一致性、最终一致性。如果要实现强一致性的话，那么就需要引入一个协调者，比如Seata、TCC。如果是要实现最终一致性的话，使用一个**本地消息表**，然后使用MQ作为消息发送的中间商。

> 最终一致性的话，是将分布式事务分成本地事务和消息事务两部分，本地事务是在本地数据库中进行提交和回滚，而消息事务是将消息写入到消息中间件中，实现消息的可靠性和顺序性。
>
> 主要逻辑就是在本地事务中在数据入库的时候将本地事务和本地消息一起入库，保证原子性，在成功之后，通过MQ发送消息，消费者将消息消费到之后更改自己的本地数据，也就是自己的本地事务，一旦自己的本地事务提交，伴随着MQ的消息消费，我们将本地消息表更新，也就意味着事务的结束，逻辑上的两个本地事务变成一个原子性。

#### 分布式理论

CAP理论。C 指的是一致性，A指的是可用性，P指的是分区容错性。CAP是不可能三者同时满足的，也就意味了CP或者AP系统。

- 一致性：每一次读取的时候都会收到最新的写入数据或者报错信息。
- 可用性：每一个请求都会收到响应，但是不能保证响应的是最新的写入数据。
- 分区容错性：尽管不同的节点之间可能会丢弃任意数量 的消息，系统仍然可以运行。

BASE理论：是CAP理论的延伸，核心思想是即时没有办法做到强一致性，但是可以保证最终一致性。BASE理论指的是基本可用、软状态、最终一致性。如果要做到BASE，就要使用几个手段，中间状态 + 重试 + 降级。

#### 什么是微服务架构

微服务架构就是一种软件架构风格，用于构建复杂的应用程序，将一个大型的应用拆分成一组小型、独立的服务单元，每一个服务单元可以独立部署、运行和扩展，每一个服务单元都专注于特定的业务功能，并能通过轻量级通信机制（HTTP、RPC、MQ）进行调用。

比如一个商城项目，拆分成产品服务、订单服务以及用户服务。系统中可以通过远程调用进行解耦，实现高内聚、低耦合。

#### 什么是分布式系统

分布式系统是针对于集中式来说的，先说集中式，集中系统就是将一整个系统的所有功能，包含数据库等等全部部署在一起，通过一整个系统提供对外服务。但是集中式的系统容易发生单点故障。一般的小系统可以使用单机的集中式环境。

分布式系统就是将一整个集中式系统切分成多个系统，每一个系统单独提供对外的部分功能，整个分布式系统对外提供一整套服务，对于访问分布式系统来说感知就像是在访问一台机器一样。

## Redis

### 基本的数据类型：

| 数据类型 | 存储结构的值                                        | 使用场景                                                     |
| -------- | --------------------------------------------------- | ------------------------------------------------------------ |
| String   | 可以包含任意的值，如数字、字符串、jpg或者序列化对象 | **1.** **缓存**。将常用信息、Token、图片等作为缓存放在Redis，减少数据库的访问。<br />**2.计数器。** Redis是一个单线程模型，命令执行是原子性的，可以作为数据记数作用。 |
| List     | 链表结构                                            | **1.排行榜。**如微博，有人发布微博之后，将数据置顶。<br />**2.消息队列。**利用发布订阅模型可以仿照MQ实现消息队列。 |
| Set      | 通过哈希表实现，数据不可重复                        | **点赞、点踩、收藏等**。                                     |
| Hash     | 适合存储对象                                        | **缓存。**相较于String类型更加节省空间。性能更高，但是更局限。 |
| ZSet     | 不允许重复的可提供排序的Set集合。                   | **排行榜。**有序集合使用场景。比如小说、视频做排行榜，榜单可以按照用户关注数量、更新时间、字数等打分排名。 |

### Redis为什么这么快？

- 基于内存。
- 单线程减少了上下文的切换，减少锁竞争，保证原子性。
- IO多路复用。
- 具有高级数据结构的快速查询。

### 为什么Redis要采用单线程模型？

因为Redis是基于内存的操作，CPU并不会成为Redis的瓶颈。影响最大的应该是网络带宽、内存大小。既然单线程容易实现，CPU不会成为瓶颈，顺理成章的就成了单线程的方案。

### 跳表

跳表是一种随机化的数据结构，记忆并联的链表，插入、删除、查找的复杂度均为O(logN)，跳表也是链表的一种，只不过在链表的基础上增加了跳跃的功能。

![image-20240305214432238](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20240305214432238.png)

#### Redis为啥用跳表不用平衡树？

1. 平衡树的插入和删除需要再平衡，增加了复杂度，影响更新效率。
2. 平衡树的存储效率没有跳表高。
3. 范围查找中，平衡树如果不做改造，类似于MySQLB+树，范围查询起来会比较麻烦，定位到节点之后，需要中序遍历继续找。

### Redis的数据过期策略

采用了惰性删除 + 定期删除的方式处理过期的数据。

> 定时删除：在设置Key的过期时间的时候，为这个Key创建一个定时器，让定时器在key的过期时间到达之后，对key进行删除。
>
> 惰性删除：在获取Key的时候实时判断有没有过期，过期就删除，返回nil。
>
> 定期删除：每隔一段时间执行一次删除（在Redis,conf配置文件设置，1s刷新的频率）。

### Redis内存淘汰策略

基本上就是8种。

- noeviction：不会淘汰任何的键值对，而是直接返回错误信息。
- allkeys-lru：从所有的key中选择最近最少使用的key 删除。
- volatile-lru：从设置了过期时间的key 中选择最近最少使用的key 删除。
- allkeys-random：所有的key中随机选择一个key进行删除。
- volatile-random：从所有的key中随机选择一个key删除。
- volatile-ttl：从设置了过期时间的key中选择剩余时间最短的key删除。
- volatile-lfu：在设置过期时间的键值对中，访问频率最低的一个。
- allkeys-lfu：所有的键值对中选择访问频率最低的一个。

### Redis缓存击穿、缓存穿透、缓存雪崩

#### Redis缓存击穿

解释：一些十分热点的数据某一个时间点失效了，但是此时存在大量请求请求到了这些失效的数据，那么就会访问到数据库中，打垮数据库。

解决：

- 预热：在Redis高峰访问的时候将一些热点数据提前存储到Redis中，加大这些热点数据的实时调整，现场监控哪些数据是热点数据，实时调整key的过期时长。
- 枷锁排队：既然请求很高，那么我们就对这个请求的部分加锁，每次只能一个请求去数据库中查询，但是效率很低。

#### Redis缓存穿透

解释：访问到一个Null 的数据，缓存和数据库中都没有数据。

解决：

- 缓存空值：如果某一个请求访问到的数据是空值，那么我们将这个空值同步到Redis中，设置过期时间短一点，好让这个key过期。
- 采用布隆过滤器：布隆过滤器不存在的一定不存在，但是存在的不一定存在。比如哈希槽的数量、更多的哈希算法，只要将哈希的位置分散开即可。
- 增加前置校验：比如有一些一定不会存在的数据，比如小于零的时候，那么其实就可以直接过滤掉。

#### Redis缓存雪崩

解释：大量的热点key失效，导致大量的请求达到数据库，造成库垮掉了。

解决：

- 设置永不过期：热点数据永不过期。
- 将失效时间随机：设置缓存时间加上一个随机值，避免缓存在同一个时间失效。



### Redis集群的三种模式

#### 主从模式

主从架构其实就是将redis节点设置成一个主节点，多个从节点。其中主节点是处理写操作和读操作，但是从节点只能处理读操作。缺点就是如果出现了节点故障需要进行人工干预，手动处理。

#### 哨兵模式

针对与主从模式的问题，哨兵模式对其进行了处理，会借助Sentinel进行哨兵监控。哨兵节点一般是一种特殊的Redis节点，用于监控主节点和从节点的状态，如果主节点发生问题，哨兵节点会进行监控和在选举。

哨兵节点会向各个节点发送PING命令，其他各个节点会根据这个请求命令响应PONG，如果一定时间哨兵节点没有收到PONG响应，就会将这个节点设置成主观下线。如果一个主节点被多次设置成主观下线，那么就会设置成客观下线。

之后就是进行选举新节点的过程，也就是故障转移的过程。他会从其他的从节点选举出一个可以作为主节点。选举的时候其实有一个选举的算法：

> Raft算法：哨兵节点会进行选举，1. 如果某一个节点的投票数量大于所有哨兵节点的一半。2. 同时如果某一个节点拿到的票数大于等于哨兵配置文件中的quorum值，就会完成选举成功。

#### 数据分片

是一个Redis十分推荐的 分布式集群方案，将数据自动分片到多个节点上，一个节点就是一个主从架构的部分。

Redis Cluster能够检测节点的故障，当一个节点失去连接或者不可达的时候，会将其标记成不可用，并从节点中提升一个新的主节点。

Cluster是一个真正意义上的集群部分，每一个节点都可以单独的对外提供服务，实现了高可用，即时一个节点宕机，仍然不会影响最终系统的可用性。







### Redisson的看门狗机制怎么实现的？

如果主动设置了过期时间就不进行续期，默认的是30s，并且每10S 循环触发下一次的续期，每一次续期30s。如果当前的id不存在了，代表解锁了，就不进行续期。

主要就是3个步骤：**自动续租、续期时长、停止续期**。

**自动续租：**当Redission获取一个分布式锁的时候，如果没有指定过期时间，WatchDog就会通过Netty启动一个后台任务，定期向redis发送一个命令，重新设置锁的过期时间，通常是租约时间的1/3.

**续期时长：**默认的情况下，10s做一次续期，时长是30s。

**停止续期：**锁被释放的时候，WatchDog会自动停止对应的锁的续约任务。

使用续约的命令是通过LUA脚本做一个院子操作。

#### WatchDog一直续期，那么客户端挂了怎么办？

先给出答案：客户端挂了，到时间就会自动释放，并不会一直续期，拿着锁不释放。

Redisson是基于JVM虚拟机运行的，所以说如果客户端挂机了，Redisson就会失去作用，那么到了期限之后自动就会释放锁。

#### WatchDog如果解锁失败，会不会一直续期？

答案是不会的，在实现这部分的时候。

在解锁的过程中如果出现了异常，还是说解锁失败了，其实都会将本地的续期任务停止，由此其实并不会一直续期。

其中的原理：其实就是在unLockInnerAsync方法和future.handle()方法上，首先进行解锁的操作，无论是否解锁成功都会走到future.handle()方法上，那么在这个handle()方法中就会携带着异常信息进行操作处理：

- 如果上一步出现异常或者失败，那么就会携带者异常信息进入下一步。
- 如果上一步没有出现错误，那么Throwable就是null值。









## MYSQL

### 1. MYsql中有那些锁？

#### 全局锁

其实全局锁锁的就是整个数据库，锁住之后，所有的增删改操作都会被阻塞，不会被执行。

添加全局锁的命令：

```sql
flush tables with read Lock
```

释放全局锁的命令

```sql
unlock tables
```

应用场景：用来做全库逻辑备份，在备份数据库的期间，不会因为数据或者表结构的改变而影响数据的更新，而出现的备份的文件数据与预期不同。

加上全局锁，意味着库中的数据只是出于只读状态，如果数据库中包含很多数据，备份机会花费很长时间，关键是备份期间，业务只能只读的话，就会造成业务停滞。

如果要是想用一种方法代替全局锁，可以利用事务隔离级别中的RR可重复读级别，其本身就是利用ReadView来进行线程隔离，将当前的的数据进行一次快照保存，整个事务都会对这个ReadView进行操作，得益于MVCC的支持，业务逻辑中仍然可以对数据进行更新操作。

#### 表级锁

##### 表锁

可以对某一张表加表锁，使用以下命令：

```sql
lock table stu read; -- 加上读锁
lock table stu write; -- 加上写锁
```

表锁除了会限制别的线程来进行数据的读写之外，还会对自己线程接下来的读写操作。

释放锁的操作：

```sql
unclock tables;
```

不过由于表锁的粒度太大，Innoda在锁的层面做了更细力度的划分，也就是行锁，粒度更细。

##### 元数据锁

MDL。我们不用显示的指示数据库的操作，本身就帮我们做了元数据锁的处理。

- 对一张表进行CRUD操作时候，加的是MDL读锁。
- 对一张表的表结构进行修改的时候，加的是MDL写锁。

MDL为了是保证用户对于表进行CRUD的时候，防止线程对这个表结构做了更改。

##### 意向锁

- 在使用InnoDB引擎的表在某一些记录上加上[共享锁]的时候，需要先在表级别加上一个[意向共享锁]；
- 在使用InnoDB引擎的表在某一些记录上加上[独占锁]的时候，需要先在表级别加上一个[意向独占锁];

当执行插入、更新、删除操作，需要先对表加上[意向独占锁]，然后对该记录加独占锁。

普通的查询并不需要加锁，是利用MVCC机制进行一致性读，无锁操作。

意向锁其实就是为了减少遍历表的开销，增加效率。

有了意向锁，由于会在记录加上独占锁前，先会加上表级别的意向独占锁，那么在加独占表锁时，直接查该表是否是意向独占锁，如果是的话，意味着表里面有了记录被加了独占锁，这样就不用遍历表的结构。

#### 行级锁

##### 记录锁

分成S锁和X锁。

- 当一个事务对某一条记录加了S锁，那么其他事务也是可以对这个记录加S锁，但是不可以对该记录加X锁。
- 当某一个事务对某一条记录加上X锁，那么其他事务对这个记录就不能添加X锁，同时也不能加S锁，由于S锁和X锁不兼容。

##### 间隙锁

只存在于RR级别，目的是为了解决RR级别下出现的幻读的现象。

假设存在一个间隙锁的范围id为(3,5)，那么其他事务就无法插入id = 4这条记录了，这样就有效防止幻读的现象发生。

##### 临键锁

 临键锁是记录锁和间隙锁的组合，锁定的是一个范围，并且锁定了记录本身。

假设有一个范围为(3,5]的临键锁，那么其他事务并不能插入id = 4的记录，也不能修改id = 5的记录。

临键锁是包含间隙锁 + 记录锁的，如果一个事务获取了X型的临键锁，那么另一个事务在获取X型的临键锁的时候会被阻塞。

### 2. 索引覆盖和索引下推

索引覆盖指的是查询一个语句的执行是只从索引中就可以取到，不必从数据表中取得。没有了回表的操作，既可以是索引覆盖。

索引下推是MySQL5.6版本中提供的一项索引优化功能，它允许存储引擎在遍历过程中，执行部分where子句的判断条件，直接过滤掉不满足条件的记录，从而减少回表次数，提升查询效率。比如本来表中存在一个组合索引（a,b），

```sql
select * from table where a = "abdn" and b = 18; -- 这是按照字段a = "abdn"和字段b = 18岁进行查询。
```

如果没有索引下推，那么就会在查询到a = "abdn"的时候进行回表，但是存在了索引下推的话，就会在判断 a = "abdn"的同时判断and b = 18岁的条件，直接减少了回表操作。



## 并发

### 1. AQS

抽象队列同步器，是很多同步器的基础框架，比如ReentrantLock、CountDownLatch、Semaphore等都是基于AQS实现的。**AQS内部维护了一个FIFO队列和一个volatile的Int类型的state变量，在state =1 的时候表示这个对象锁已经被占用了，state变量的值的修改需要通过CAS来实现。**

FIFO队列是实现多线程的排队工作，当线程加锁失败之后，该线程会被封装成一个Node节点来放置到队列尾部。

当持有锁的线程释放锁之后，AQS会将等待队列中的第一个线程唤醒，并让其重新尝试获取锁。

#### 同步状态--state

AQS使用了一个volatile Int类型的成员变量表示同步状态，在state = 1 的时候表示当前对象锁已经被占有了，提供了三种基本方法来操作同步状态，getState()、setState()、CAS。这些方法允许在不同的同步实现中自定义资源的共享和独占方式。

#### FIFO队列--Node

当线程尝试获取资源失败时，AQS会将线程包装成一个Node节点，并将其插入同步队列的尾部。在资源可用的情况下，队列头部的节点会尝试再次获取资源。就这样，一个有一个的Node被连接到一起，就成为了一个FIFO的队列。

### 2. CompletableFuture底层如何实现

是一个Java8的新特性，提供了一种简单的方法来实现异步编程和任务组合。它的底层实现主要涉及到了几个重要的手段。如CompletableFuture链式异步处理、ForkJoinPool线程池、以及CountDownLatch控制计算状态、通过CompletionException捕获异常。

**CompletableFuture内部采用了一种链式的结构来处理异步计算结果，**每个CompletableFuture都有一个预支关联的Completion链，它包含多个Completion阶段，每个阶段都代表了一个异步操作，并且可以指定它所依赖前一个阶段计算结果。

**CompletableFuture还使用了一种事件驱动的机制来处理异步计算的完成事件。**在一个Future对象上注册Completion阶段完成之后，它会触发一个完成事件，然后Future对象会执行与之关联的下一个Completion阶段。

CompletableFuture异步计算是通过线程池来实现的。**CompletableFuture在内部使用了一个ForkJoinPool线程池来执行异步任务。**当我们创建一个CompletableFuture对象时，它会在内部创建一个任务，并且提交到ForkJoinPool去执行。

使用场景是适合**异步编排**。

我们的项目中就是使用到了这个Future，将用户可能输入的很多的









## 场景题

### 1. 出现超卖问题的原因以及怎么解决？

出现超卖的问题是因为并发问题，有两个并发线程，同时查询库存，这时数据库中库存剩余1 ，所以两个线程都会得到1的库存，然后经过库存校验之后分别进行库存扣减，最终导致库存被扣减成负数。

> 如果要解决这个问题，最主要的问题就是实现库存扣减过程中原子性和有序性。

- **数据库扣减**

数据库中进行库存扣减是最容易想到的方案，这个方案实现起来非常简单。

在扣减过程中，想要保证事务的原子性和有序性，我们可以采用加锁的方式。无论是悲观锁还是乐观锁都是可以实现的。

如果是悲观锁的话，就会导致很多请求被迫阻塞并且排队，那么如果并发请求量很大的话，就可能直接把数据库给拖垮。

如果是乐观锁的话，可以使用版本号的方式来控制有序执行，但是

- 

### 2. 如何设计一个购物车的功能？







## 面经

















## 笔试题

### 令牌桶算法

```java
public class Lingpaitong {
    // ；令牌桶容量
    private final int capacity;

    // 令牌产生的速率
    private final int rate;

    // 当前令牌数量
    private int tokens;

    // 最后的令牌补充时间
    private long lastRefillTime;


    public Lingpaitong(int capacity, int rate) {
        this.capacity = capacity;
        this.rate = rate;
        this.tokens = capacity;
        this.lastRefillTime = System.currentTimeMillis();
    }

    /**
     * 尝试获取令牌  -》需要加锁，因为可能是存在大量的线程在同时尝试获取令牌
     * 如果想要调用这个方法，返回值是true的话说明是允许通行，否则是失败
     */
    public synchronized boolean tryAcquire() {
        refillTokens();
        if(tokens > 0) {
            tokens --;
            return true;
        }else {
            return false;
        }
    }

    /**
     * 补充令牌
     */
    public void refillTokens() {
        long currentTime = System.currentTimeMillis();

        // 计算自上次补充令牌以来经过的时间
        long elapsedTime = currentTime - lastRefillTime;

        if (elapsedTime > 0) {
            int newTokens = (int) (elapsedTime * rate / 1000);
            tokens = Math.min(tokens+newTokens, capacity);
            lastRefillTime = currentTime;
            System.out.println("补充令牌：" + newTokens + "，当前令牌数量：" + tokens);
        }
    }
}

```

